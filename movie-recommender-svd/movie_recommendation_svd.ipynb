{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Project: Movie Recommendation System   \n",
        "\n",
        "##Name: Amritha Prakash\n"
      ],
      "metadata": {
        "id": "SKEeP7hPW2p9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ONIP_eF-XJWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Singular Value Decomposition**\n",
        "\n",
        "Singular Value Decomposition, or SVD, is a mathematical technique used in many fields such as signal processing, statistics, and machine learning, particularly in the context of recommendation systems. It's a method for decomposing a matrix into three other matrices that reveal its underlying structure.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Basic Concepts\n",
        "\n",
        "### Matrices\n",
        "- **Matrix**: A rectangular array of numbers.\n",
        "- **Dimension of a Matrix**: Given in the form of rows × columns.\n",
        "\n",
        "### Decomposition\n",
        "- **Decomposition**: Breaking down a complex matrix into simpler, understandable parts.\n",
        "\n",
        "## What is SVD?\n",
        "\n",
        "```\n",
        "SVD breaks down any given matrix A into three separate matrices named U, Σ and V*\n",
        "ie. A = UΣV*\n",
        "```\n",
        "Where the components are:\n",
        "```\n",
        "- A: Original matrix.\n",
        "- U: Left singular vectors (orthogonal matrix).\n",
        "- Σ: Diagonal matrix of singular values (non-negative).\n",
        "- V*: Right singular vectors (conjugate transpose of V , an orthogonal matrix).\n",
        "```\n"
      ],
      "metadata": {
        "id": "p2JOQLRsXJym"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aPG26djjXkO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Where do we use SVDs?\n",
        "\n",
        "### Applications in Recommendation Systems\n",
        "\n",
        "In recommendation systems, SVD is used to predict unknown preferences by decomposing a large matrix of user-item interactions into factors representing latent features. It helps in capturing the underlying patterns in the data.\n",
        "\n",
        "### Process\n",
        "\n",
        "1. **Matrix Creation**: Start with a matrix where rows represent users, columns represent items, and entries represent user ratings.\n",
        "2. **Apply SVD**: Decompose this matrix using SVD.\n",
        "3. **Latent Features**: The decomposition reveals latent features that explain observed ratings.\n",
        "4. **Prediction**: Use the decomposed matrices to predict missing ratings.\n",
        "\n",
        "### Advantages of an SVD\n",
        "- Effective at uncovering latent features in the data.\n",
        "- Reduces dimensionality, making computations more manageable.\n",
        "\n",
        "### Limitations of an SVD\n",
        "- Assumes linear relationships in data.\n",
        "- Sensitive to missing data and outliers."
      ],
      "metadata": {
        "id": "_wbfkndKYspG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HGjTg-dGYtG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Through this project, will build a movie recommendation system using an SVD\n",
        "\n",
        "\n",
        "#### Dataset being used : **Movielens 100k dataset**\n",
        "\n",
        "- This specific dataset, often referred to as \"ml-100k,\" contains 100,000 ratings from 943 users on 1,682 movies. The data was collected through the MovieLens website during the seven-month period from September 19th, 1997 to April 22nd, 1998.\n",
        "\n",
        "- **Data Structure**: The dataset includes user ratings that range from 1 to 5. Additionally, it provides demographic information about the users (age, gender, occupation, etc.) and details about the movies (titles, genres).\n",
        "\n",
        "- **Usage**: It's a standard dataset used for implementing and testing recommender systems. Its size is manageable, making it a popular choice for educational purposes and for initial experimentation with recommendation algorithms.\n",
        "\n",
        "- **Significance**: The diversity in the dataset, both in terms of users and movie genres, provides a rich ground for analyzing different recommendation strategies, testing algorithms like SVD, and understanding user preferences and behavioral patterns.\n",
        "\n",
        "This dataset is an excellent starting point for anyone looking to delve into the world of recommender systems and practice with real-world data.\n",
        "\n",
        "\n",
        "Now, I will write some code to understand and explore the dataset"
      ],
      "metadata": {
        "id": "6mpsLuUsYyKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this only once, you can comment out this part of the code after.\n",
        "!pip install surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-M8bESWZA0Q",
        "outputId": "66d45c93-526d-40e2-f3ee-9baa81ac1bab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m143.4/154.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (1.15.3)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2469539 sha256=2a52d0efe994542308c4dc6dbea31efe3d0382f11381e3f7bd7e864b66ca479e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "59b84f45",
        "outputId": "0b4641fe-90d4-4199-e23c-27b1cb3cbdf2"
      },
      "source": [
        "# Downgrade NumPy to a version compatible with surprise\n",
        "!pip install \"numpy<2.0\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "2c080fdfb7ac434b840d8b4e98593ad1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary modules for this project\n",
        "import pandas as pd\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "xC0P_ubXZFAF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing the dataset from pandas, run this only once, you can comment out this part of the code after.\n",
        "!pip install pandas scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0COL_01ZSYa",
        "outputId": "3d897094-2567-4d87-d69b-226394293601"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (1.1.4)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.5.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.15.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset"
      ],
      "metadata": {
        "id": "N2ddKZVXcBQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset"
      ],
      "metadata": {
        "id": "4vThM7YLZhTN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset.load_builtin('ml-100k')\n",
        "df = pd.DataFrame(data.raw_ratings, columns=[\"user\", \"item\", \"rating\", \"timestamp\"])\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfjW8Nq8Z8Ae",
        "outputId": "3f770013-59f6-4ab6-a167-ca9706385be9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  user item  rating  timestamp\n",
            "0  196  242     3.0  881250949\n",
            "1  186  302     3.0  891717742\n",
            "2   22  377     1.0  878887116\n",
            "3  244   51     2.0  880606923\n",
            "4  166  346     1.0  886397596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see the following columns:\n",
        "\n",
        "* **User ID**: A unique identifier for the user who provided the rating.\n",
        "\n",
        "* **Item ID (Movie ID)**: A unique identifier for the movie that was rated.\n",
        "\n",
        "* **Rating:** The rating given to the movie by the user. In the MovieLens 100k dataset, these ratings are typically on a scale of 1 to 5.\n",
        "\n",
        "* **Timestamp:** The time at which the rating was provided. The timestamp is usually in Unix time format, which counts seconds since the Unix epoch (January 1, 1970).\n",
        "\n"
      ],
      "metadata": {
        "id": "emPxJuXOaCbK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "odszBL76Z8nj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "hXKUFd_KcIc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for missing values\n",
        "\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5UKs5utcLkI",
        "outputId": "6f51b11c-460a-4f15-cef5-93ed05116ee0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user         0\n",
            "item         0\n",
            "rating       0\n",
            "timestamp    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting timestamps to a readable format\n",
        "\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d66PAS3zcRLk",
        "outputId": "345289f6-611a-4b28-8423-a3bcdc5fe4e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-8-3514354872.py:3: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
            "  df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  user item  rating           timestamp\n",
            "0  196  242     3.0 1997-12-04 15:55:49\n",
            "1  186  302     3.0 1998-04-04 19:22:22\n",
            "2   22  377     1.0 1997-11-07 07:18:36\n",
            "3  244   51     2.0 1997-11-27 05:02:03\n",
            "4  166  346     1.0 1998-02-02 05:33:16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DbkLNlfycWkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spliting the data to Train and Test set"
      ],
      "metadata": {
        "id": "wL7h_Yf-cd3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into a training set and a test set\n",
        "trainset, testset = train_test_split(data, test_size=0.20)\n",
        "\n",
        "# Display the number of users and items in the training set\n",
        "print(f\"Training set :\")\n",
        "print(f\"Number of users: {trainset.n_users}\")\n",
        "print(f\"Number of items: {trainset.n_items}\")\n",
        "\n",
        "# Display the first few elements of the test set\n",
        "print(f\"\\nTest set :\")\n",
        "print(testset[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeLaKa3mcgSH",
        "outputId": "b88b311a-be7a-461f-a1f1-ffcd742abfb5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set :\n",
            "Number of users: 943\n",
            "Number of items: 1648\n",
            "\n",
            "Test set :\n",
            "[('821', '70', 4.0), ('128', '118', 5.0), ('592', '236', 3.0), ('555', '748', 4.0), ('229', '286', 4.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wUeeJ_michGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning in SVD\n",
        "Hyperparameter tuning is a critical step in optimizing the performance of an SVD model. The goal is to find the best combination of parameters that results in the most accurate predictions or lowest error rates.\n",
        "\n",
        "#### Hyperparameters we will be tuning in this project\n",
        "\n",
        "1. **`n_factors`**:\n",
        "   - Represents the number of latent factors (or features) to extract from the dataset.\n",
        "   - The values `[50, 100, 150]` are chosen to test the model's performance with a varying number of factors. A higher number of factors can capture more complex patterns but may lead to overfitting and increased computation time.\n",
        "\n",
        "2. **`n_epochs`**:\n",
        "   - Refers to the number of iterations over the entire dataset during training.\n",
        "   - The values `[20, 30]` provide a range to evaluate whether more iterations improve model performance or lead to overtraining.\n",
        "\n",
        "3. **`lr_all`** (Learning Rate):\n",
        "   - Determines the step size at each iteration while moving toward a minimum of the loss function.\n",
        "   - The values `[0.005, 0.010]` are chosen to test how fast the model learns. A smaller learning rate may lead to more precise convergence but requires more epochs.\n",
        "\n",
        "4. **`reg_all`** (Regularization Term):\n",
        "   - Helps prevent overfitting by penalizing larger model parameters.\n",
        "   - The values `[0.02, 0.1]` offer a range to assess the impact of regularization on model performance. Higher regularization can reduce overfitting but may lead to underfitting."
      ],
      "metadata": {
        "id": "o_D4ACCJc1za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a grid of SVD hyperparameters explained above for tuning\n",
        "param_grid = {\n",
        "    'n_factors': [50, 100, 150],\n",
        "    'n_epochs': [20, 30],\n",
        "    'lr_all': [0.005, 0.010],\n",
        "    'reg_all': [0.02, 0.1]\n",
        "}\n"
      ],
      "metadata": {
        "id": "75lk4V8Kc2eK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I will train the model with the following parameters:\n",
        "\n",
        "1. **`SVD`**:\n",
        "   - This is the recommendation algorithm being tuned. SVD is a popular algorithm used in recommendation systems, particularly for matrix factorization.\n",
        "\n",
        "2. **`param_grid`**:\n",
        "   - This is a dictionary where keys are hyperparameter names, and values are lists of parameter settings to try as values. It defines the grid of parameters that will be tested.\n",
        "   - Example: If `param_grid` is `{'n_factors': [50, 100], 'lr_all': [0.005, 0.01]}`, GridSearchCV will evaluate the SVD algorithm for all combinations of `n_factors` and `lr_all` from these lists.\n",
        "\n",
        "3. **`measures=['RMSE', 'MAE']`**:\n",
        "   - These are the performance metrics used to evaluate the algorithm.\n",
        "   - `RMSE` stands for Root Mean Square Error, and `MAE` stands for Mean Absolute Error. Both are common metrics for evaluating the accuracy of prediction algorithms, with lower values indicating better performance.\n",
        "\n",
        "4. **`cv=3`**:\n",
        "   - This specifies the number of folds for cross-validation.\n",
        "   - In this context, `cv=3` means that a 3-fold cross-validation will be used. The dataset will be split into three parts: in each iteration, two parts will be used for training, and one part will be used for testing. This process repeats three times, each time with a different part used for testing."
      ],
      "metadata": {
        "id": "n3i4cqgmfqMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV\n",
        "from surprise import SVD, Dataset, Reader, accuracy\n",
        "\n",
        "# Perform grid search with cross-validation to find the best hyperparameters for our model\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['RMSE', 'MAE'], cv=3)\n",
        "gs.fit(data)"
      ],
      "metadata": {
        "id": "GvsEYzBBfdnI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best score and parameters\n",
        "print(f\"Best RMSE: {gs.best_score['rmse']}\")\n",
        "print(f\"Best parameters: {gs.best_params['rmse']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyTazbZffvXz",
        "outputId": "204cc37d-e220-45ad-a40b-1f3df95fe899"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE: 0.9205828491341563\n",
            "Best parameters: {'n_factors': 150, 'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - Use the best model. Use best_estimator function on gs\n",
        "algo = gs.best_estimator['rmse']"
      ],
      "metadata": {
        "id": "jIILj2LFf2xy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - Train and test split. Make sure test_size is 0.25\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "# TODO - Fit the trainset to train the model\n",
        "algo.fit(trainset)\n",
        "# TODO - Make predictions on the testset\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# TODO - Calculate and print RMSE on the predictions made\n",
        "accuracy.rmse(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW-ySTcGf6Mt",
        "outputId": "c6a7ba03-f183-4bc9-f5f2-5b9b8f0d52b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9183\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9182764275230733"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict rating for a user and item\n",
        "user_id = '196'  # replace with a specific user ID\n",
        "item_id = '302'  # replace with a specific item (movie) ID\n",
        "predicted_rating = algo.predict(user_id, item_id)\n",
        "print(f\"Predicted rating for user {user_id} and item {item_id}: {predicted_rating.est}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VKBmfTuf87t",
        "outputId": "4cd51647-3130-43a5-8e41-d1be4ab8b090"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 196 and item 302: 4.184095163685722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To inspect the predictions in detail, let's print the first 10 predictions made by the model\n",
        "for idx, prediction in enumerate(predictions[:10]):\n",
        "    print(f'Prediction {idx}: User {prediction.uid} and item {prediction.iid} has true rating {prediction.r_ui}, and the predicted rating is {prediction.est}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3PArBajf_8U",
        "outputId": "49a6866e-42fa-4d5f-d31b-98f5424f24c6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction 0: User 168 and item 118 has true rating 4.0, and the predicted rating is 3.829540409114962\n",
            "Prediction 1: User 342 and item 134 has true rating 4.0, and the predicted rating is 4.312825773828511\n",
            "Prediction 2: User 807 and item 418 has true rating 4.0, and the predicted rating is 4.056131361604987\n",
            "Prediction 3: User 22 and item 433 has true rating 3.0, and the predicted rating is 4.077679661786188\n",
            "Prediction 4: User 405 and item 1113 has true rating 1.0, and the predicted rating is 2.4968975598327474\n",
            "Prediction 5: User 314 and item 120 has true rating 3.0, and the predicted rating is 2.6957245175505404\n",
            "Prediction 6: User 405 and item 1229 has true rating 1.0, and the predicted rating is 1.2334730481870217\n",
            "Prediction 7: User 537 and item 346 has true rating 3.0, and the predicted rating is 3.3312579299203025\n",
            "Prediction 8: User 899 and item 64 has true rating 4.0, and the predicted rating is 4.2146191350659965\n",
            "Prediction 9: User 844 and item 45 has true rating 4.0, and the predicted rating is 3.817372551965912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us round the values of the predictions so that it falls within the rating categories of [1.0, 2.0, 3.0, 4.0, 5.0]"
      ],
      "metadata": {
        "id": "I5uU9qtWgHzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO - Round the prediction.est variable being printed. Use python's default rounding function to achieve this\n",
        "import math\n",
        "\n",
        "for idx, prediction in enumerate(predictions[:10]):\n",
        "    temp = math.ceil(int(prediction.est))\n",
        "    print(f'Prediction {idx}: User {prediction.uid} and item {prediction.iid} has true rating {prediction.r_ui}, and the predicted rating is {round(prediction.est)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34gpNnDagIni",
        "outputId": "67ea7432-82c3-4de5-b930-62570505ff0b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction 0: User 168 and item 118 has true rating 4.0, and the predicted rating is 4\n",
            "Prediction 1: User 342 and item 134 has true rating 4.0, and the predicted rating is 4\n",
            "Prediction 2: User 807 and item 418 has true rating 4.0, and the predicted rating is 4\n",
            "Prediction 3: User 22 and item 433 has true rating 3.0, and the predicted rating is 4\n",
            "Prediction 4: User 405 and item 1113 has true rating 1.0, and the predicted rating is 2\n",
            "Prediction 5: User 314 and item 120 has true rating 3.0, and the predicted rating is 3\n",
            "Prediction 6: User 405 and item 1229 has true rating 1.0, and the predicted rating is 1\n",
            "Prediction 7: User 537 and item 346 has true rating 3.0, and the predicted rating is 3\n",
            "Prediction 8: User 899 and item 64 has true rating 4.0, and the predicted rating is 4\n",
            "Prediction 9: User 844 and item 45 has true rating 4.0, and the predicted rating is 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "idejmJFti3S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics to Evaluate:\n",
        "1. RMSE (Root Mean Squared Error)   \n",
        "Measures the square root of the average squared differences between predicted and actual ratings. Lower is better.\n",
        "\n",
        "2. MAE (Mean Absolute Error)   \n",
        "Measures the average of the absolute differences between predicted and actual ratings. Also, lower is better."
      ],
      "metadata": {
        "id": "y1WppUd7jW9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import accuracy\n",
        "\n",
        "# Calculate and print RMSE\n",
        "rmse = accuracy.rmse(predictions)\n",
        "\n",
        "# Calculate and print MAE\n",
        "mae = accuracy.mae(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVFNDBUOjaxE",
        "outputId": "84db771e-9692-4d64-f9bc-667fd1a0636c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9183\n",
            "MAE:  0.7279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSE :\n",
        "* This means that, on average, the predicted rating deviates from the true rating by about 0.92 on a scale of 1 to 5.\n",
        "\n",
        "* Because RMSE penalizes larger errors more heavily than MAE, a value below 1.0 is actually quite decent for movie recommendation tasks.\n",
        "\n",
        "* It suggests the model is generally predicting ratings fairly close to what users actually gave, but occasionally makes bigger errors.\n",
        "\n",
        "MAE :\n",
        "* This means the average absolute difference between predicted and true ratings is about 0.73.\n",
        "\n",
        "* Since MAE treats all errors equally, this tells us the model is consistently within about 0.7 stars of the true rating, which is also acceptable."
      ],
      "metadata": {
        "id": "mwjj6jsUjpsR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lp8pGQ6uje0e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}